{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea84244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x28735f9c410>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "os.environ[\"HF_HOME\"] = str(here(\"cache/huggingface\"))\n",
    "import lightning as L\n",
    "from importlib import reload\n",
    "import sys\n",
    "sys.path.append(str(here()))\n",
    "from models import model_definitions as MD\n",
    "import torch\n",
    "import pandas as pd\n",
    "reload(MD)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "data_module_3 = MD.GoEmotionsDataModule(pd.read_parquet(here(\"data/goemotions_3.parquet\")))\n",
    "data_module_7 = MD.GoEmotionsDataModule(pd.read_parquet(here(\"data/goemotions_7.parquet\")))\n",
    "data_module_28 = MD.GoEmotionsDataModule(pd.read_parquet(here(\"data/goemotions_28.parquet\")))\n",
    "metrics = MD.MetricsCallback()\n",
    "\n",
    "def make_trainer():\n",
    "  return L.Trainer(\n",
    "    max_epochs=15,\n",
    "    max_time={\"minutes\": 10},\n",
    "    callbacks=[\n",
    "      # metrics,\n",
    "    ],\n",
    "    deterministic=True,\n",
    "    default_root_dir=here(\"cache/lightning\"),\n",
    "    enable_checkpointing=True,\n",
    "    fast_dev_run=False,\n",
    "    accelerator=\"auto\", \n",
    "  )\n",
    "\n",
    "trainer = make_trainer()\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aff64c",
   "metadata": {},
   "source": [
    "# Distil Bert finetuned (cross entropy loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da517a3",
   "metadata": {},
   "source": [
    "## 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77b532df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Plancha\\emotion-recognition\\.pixi\\envs\\gpu\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4960583c3e87459f9cba688a47f2330f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.4729805886745453\n",
      "    test_expectedNDCG       0.6360554099082947\n",
      "    test_f1_interest        0.5236578583717346\n",
      "      test_f1_stand         0.5838572978973389\n",
      "        test_nDGC           0.9337419867515564\n",
      "        test_rmse           0.25479617714881897\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.4729805886745453,\n",
       "  'test_f1_stand': 0.5838572978973389,\n",
       "  'test_f1_interest': 0.5236578583717346,\n",
       "  'test_rmse': 0.25479617714881897,\n",
       "  'test_nDGC': 0.9337419867515564,\n",
       "  'test_expectedNDCG': 0.6360554099082947}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD)\n",
    "distil_3 = MD.DistilBertFinetune(n_emotions=3)\n",
    "if False:    \n",
    "  trainer.fit(\n",
    "    distil_3,\n",
    "    datamodule=data_module_3,\n",
    "  )\n",
    "else:\n",
    "  distil_3 = MD.DistilBertFinetune.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_finetuned_3_14epchs.ckpt\"),\n",
    "    n_emotions=3,\n",
    "  )\n",
    "out = trainer.test(\n",
    "  distil_3,\n",
    "  datamodule=data_module_3,\n",
    ")\n",
    "del distil_3\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81704917",
   "metadata": {},
   "source": [
    "## 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0136d052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872e902212274666b7f16a213944bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.2803645133972168\n",
      "    test_expectedNDCG       0.41903358697891235\n",
      "    test_f1_interest        0.2714906632900238\n",
      "      test_f1_stand         0.23877769708633423\n",
      "        test_nDGC           0.8969202041625977\n",
      "        test_rmse           0.18574778735637665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.2803645133972168,\n",
       "  'test_f1_stand': 0.23877769708633423,\n",
       "  'test_f1_interest': 0.2714906632900238,\n",
       "  'test_rmse': 0.18574778735637665,\n",
       "  'test_nDGC': 0.8969202041625977,\n",
       "  'test_expectedNDCG': 0.41903358697891235}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD)\n",
    "distil_7 = MD.DistilBertFinetune(n_emotions=7)\n",
    "if False:    \n",
    "  trainer.fit(\n",
    "    distil_7,\n",
    "    data_module=data_module_7,\n",
    "  )\n",
    "else:\n",
    "  distil_7 = MD.DistilBertFinetune.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_finetuned_7_14epchs.ckpt\"),\n",
    "    n_emotions=7,\n",
    "  )\n",
    "out = trainer.test(\n",
    "  distil_7,\n",
    "  datamodule=data_module_7\n",
    ")\n",
    "del distil_7\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a04f0b",
   "metadata": {},
   "source": [
    "## 28 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd11ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e0bfd44f3f452b9205e8a76e6c1c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.11658827215433121\n",
      "    test_expectedNDCG       0.2731611430644989\n",
      "    test_f1_interest        0.09542364627122879\n",
      "      test_f1_stand         0.09084004908800125\n",
      "        test_nDGC           0.8161150217056274\n",
      "        test_rmse           0.11110500991344452\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.11658827215433121,\n",
       "  'test_f1_stand': 0.09084004908800125,\n",
       "  'test_f1_interest': 0.09542364627122879,\n",
       "  'test_rmse': 0.11110500991344452,\n",
       "  'test_nDGC': 0.8161150217056274,\n",
       "  'test_expectedNDCG': 0.2731611430644989}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD)\n",
    "distil_28 = MD.DistilBertFinetune(n_emotions=28)\n",
    "trainer = make_trainer()\n",
    "if False:    \n",
    "  trainer.fit(\n",
    "    distil_28,\n",
    "    datamodule=data_module_28,\n",
    "  )\n",
    "else:\n",
    "  distil_28 = MD.DistilBertFinetune.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_finetuned_28_11epchs.ckpt\"),\n",
    "    n_emotions=28,\n",
    "  )\n",
    "out = trainer.test(\n",
    "  distil_28,\n",
    "  datamodule=data_module_28,\n",
    ")\n",
    "del distil_28\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624fea",
   "metadata": {},
   "source": [
    "# Distil Bert finetuned (DCG loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3961d",
   "metadata": {},
   "source": [
    "## 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8999fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b999eaad550a42649f97616881992fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.5900861024856567\n",
      "    test_expectedNDCG       0.6335099339485168\n",
      "    test_f1_interest        0.4503559172153473\n",
      "      test_f1_stand         0.7225136756896973\n",
      "        test_nDGC           0.9327593445777893\n",
      "        test_rmse           0.33047133684158325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.5900861024856567,\n",
       "  'test_f1_stand': 0.7225136756896973,\n",
       "  'test_f1_interest': 0.4503559172153473,\n",
       "  'test_rmse': 0.33047133684158325,\n",
       "  'test_nDGC': 0.9327593445777893,\n",
       "  'test_expectedNDCG': 0.6335099339485168}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD) # DistilBertFinetuneOnDCG\n",
    "distil_dcg_3 = MD.DistilBertFinetuneOnDCG(n_emotions=3)\n",
    "trainer = make_trainer()\n",
    "if False:    \n",
    "  trainer.fit(\n",
    "    distil_dcg_3,\n",
    "    datamodule=data_module_3,\n",
    "  )\n",
    "else:\n",
    "  distil_dcg_3 = MD.DistilBertFinetuneOnDCG.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_onDCG_3_10epchs.ckpt\"),\n",
    "    n_emotions=3,\n",
    "  ) \n",
    "out = trainer.test(\n",
    "  distil_dcg_3,\n",
    "  datamodule=data_module_3,\n",
    ")\n",
    "del distil_dcg_3\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866509f9",
   "metadata": {},
   "source": [
    "## 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a86f17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19d6f24d576483a90c02def102e03be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.42078444361686707\n",
      "    test_expectedNDCG       0.4177568554878235\n",
      "    test_f1_interest        0.18308162689208984\n",
      "      test_f1_stand         0.39270398020744324\n",
      "        test_nDGC           0.8886398077011108\n",
      "        test_rmse           0.2857814431190491\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.42078444361686707,\n",
       "  'test_f1_stand': 0.39270398020744324,\n",
       "  'test_f1_interest': 0.18308162689208984,\n",
       "  'test_rmse': 0.2857814431190491,\n",
       "  'test_nDGC': 0.8886398077011108,\n",
       "  'test_expectedNDCG': 0.4177568554878235}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD)\n",
    "distil_dcg_7 = MD.DistilBertFinetuneOnDCG(n_emotions=7)\n",
    "trainer = make_trainer()\n",
    "if False:    \n",
    "  trainer.fit(\n",
    "    distil_dcg_7,\n",
    "    datamodule=data_module_7,\n",
    "  )\n",
    "else:\n",
    "  distil_dcg_7 = MD.DistilBertFinetuneOnDCG.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_onDCG_7_10epchs.ckpt\"),\n",
    "    n_emotions=7,\n",
    "  )\n",
    "  \n",
    "out = trainer.test(\n",
    "  distil_dcg_7,\n",
    "  datamodule=data_module_7,\n",
    ")\n",
    "del distil_dcg_7\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c7a7b",
   "metadata": {},
   "source": [
    "## 28 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3641944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8aa6fd0af34dd29f1a415d18a76669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_cross_entropy       0.4481115937232971\n",
      "    test_expectedNDCG       0.2697453200817108\n",
      "    test_f1_interest       0.052236463874578476\n",
      "      test_f1_stand         0.3579895496368408\n",
      "        test_nDGC           0.7873262763023376\n",
      "        test_rmse            0.342868834733963\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_cross_entropy': 0.4481115937232971,\n",
       "  'test_f1_stand': 0.3579895496368408,\n",
       "  'test_f1_interest': 0.052236463874578476,\n",
       "  'test_rmse': 0.342868834733963,\n",
       "  'test_nDGC': 0.7873262763023376,\n",
       "  'test_expectedNDCG': 0.2697453200817108}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(MD)\n",
    "distil_dcg_28 = MD.DistilBertFinetuneOnDCG(n_emotions=28)\n",
    "trainer = make_trainer()\n",
    "if False:\n",
    "  trainer.fit(\n",
    "    distil_dcg_28,\n",
    "    datamodule=data_module_28,\n",
    "  )\n",
    "else:\n",
    "  distil_dcg_28 = MD.DistilBertFinetuneOnDCG.load_from_checkpoint(\n",
    "    here(\"models/model_checkpoints/distil_bert_onDCG_28_10epchs.ckpt\"),\n",
    "    n_emotions=28,\n",
    "  )\n",
    "out = trainer.test(\n",
    "  distil_dcg_28,\n",
    "  datamodule=data_module_28,\n",
    ")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6a697b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2097fe899aba4f05a0878ebc36077cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0433, 0.6453, 0.9952, 0.3850, 0.0246, 0.2627, 0.0545, 0.0138, 0.9210,\n",
       "          0.1429, 0.0670, 0.0282, 0.2872, 0.1308, 0.5913, 0.3643, 0.8826, 0.0120,\n",
       "          0.6599, 0.0147, 0.0060, 0.0908, 0.0364, 0.0083, 0.1318, 0.5724, 0.0764,\n",
       "          0.0056]])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sample\n",
    "trainer.predict(\n",
    "  distil_dcg_28,\n",
    "  [\"I Love this\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9c11915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'n_raters', 'emotions', 'author', 'subreddit', 'link_id',\n",
       "       'parent_id', 'created_utc', 'emotion_sadness', 'emotion_unclear',\n",
       "       'emotion_love', 'emotion_gratitude', 'emotion_disapproval',\n",
       "       'emotion_amusement', 'emotion_disappointment', 'emotion_disgust',\n",
       "       'emotion_admiration', 'emotion_realization', 'emotion_annoyance',\n",
       "       'emotion_confusion', 'emotion_optimism', 'emotion_curiosity',\n",
       "       'emotion_excitement', 'emotion_caring', 'emotion_joy',\n",
       "       'emotion_remorse', 'emotion_approval', 'emotion_nervousness',\n",
       "       'emotion_embarrassment', 'emotion_surprise', 'emotion_anger',\n",
       "       'emotion_grief', 'emotion_pride', 'emotion_desire', 'emotion_relief',\n",
       "       'emotion_fear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(here(\"data/goemotions_28.parquet\")).columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
