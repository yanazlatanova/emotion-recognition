@article{netwok2020,
  title={At-scale impact of the {Net Wok}: A culinarically holistic investigation of distributed dumplings},
  author={Astley, Rick and Morris, Linda},
  journal={Armenian Journal of Proceedings},
  volume={61},
  pages={192--219},
  year=2020,
  publisher={Automatic Publishing Inc.}
}

@inproceedings{softrank,
author = {Taylor, Michael and Guiver, John and Robertson, Stephen and Minka, Tom},
title = {SoftRank: optimizing non-smooth rank metrics},
year = {2008},
isbn = {9781595939272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1341531.1341544},
doi = {10.1145/1341531.1341544},
abstract = {We address the problem of learning large complex ranking functions. Most IR applications use evaluation metrics that depend only upon the ranks of documents. However, most ranking functions generate document scores, which are sorted to produce a ranking. Hence IR metrics are innately non-smooth with respect to the scores, due to the sort. Unfortunately, many machine learning algorithms require the gradient of a training objective in order to perform the optimization of the model parameters,and because IR metrics are non-smooth,we need to find a smooth proxy objective that can be used for training. We present a new family of training objectives that are derived from the rank distributions of documents, induced by smoothed scores. We call this approach SoftRank. We focus on a smoothed approximation to Normalized Discounted Cumulative Gain (NDCG), called SoftNDCG and we compare it with three other training objectives in the recent literature. We present two main results. First, SoftRank yields a very good way of optimizing NDCG. Second, we show that it is possible to achieve state of the art test set NDCG results by optimizing a soft NDCG objective on the training set with a different discount function},
booktitle = {Proceedings of the 2008 International Conference on Web Search and Data Mining},
pages = {77–86},
numpages = {10},
keywords = {gradient descent, learning, metrics, optimization, ranking},
location = {Palo Alto, California, USA},
series = {WSDM '08}
}

@article{netwok2022,
  title={{Net Wok}++: Taking distributed dumplings to the cloud},
  author={Morris, Linda and Astley, Rick},
  journal={Armenian Journal of Proceedings},
  volume={65},
  pages={101--118},
  year=2022,
  publisher={Automatic Publishing Inc.}
}

@article{GoEmotionsDatasetOrigin,
      title={GoEmotions: A Dataset of Fine-Grained Emotions}, 
      author={Dorottya Demszky and Dana Movshovitz-Attias and Jeongwoo Ko and Alan Cowen and Gaurav Nemade and Sujith Ravi},
      year={2020},
      eprint={2005.00547},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.00547}, 
}


@article{GoEmotionsUsedWithBert,
      title={Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning}, 
      author={Kaipeng Wang and Zhi Jing and Yongye Su and Yikun Han},
      year={2024},
      eprint={2403.06108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.06108}, 
}

@inproceedings{EmotionAnalysisinNLP,
    title = "Emotion Analysis in {NLP}: Trends, Gaps and Roadmap for Future Directions",
    author = "Plaza-del-Arco, Flor Miriam  and
      Cercas Curry, Alba A.  and
      Cercas Curry, Amanda  and
      Hovy, Dirk",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.506/",
    pages = "5696--5710",
    abstract = "Emotions are a central aspect of communication. Consequently, emotion analysis (EA) is a rapidly growing field in natural language processing (NLP). However, there is no consensus on scope, direction, or methods. In this paper, we conduct a thorough review of 154 relevant NLP publications from the last decade. Based on this review, we address four different questions: (1) How are EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and which emotions are modeled? (3) Is the subjectivity of emotions considered in terms of demographics and cultural factors? and (4) What are the primary NLP applications for EA? We take stock of trends in EA and tasks, emotion frameworks used, existing datasets, methods, and applications. We then discuss four lacunae: (1) the absence of demographic and cultural aspects does not account for the variation in how emotions are perceived, but instead assumes they are universally experienced in the same manner; (2) the poor fit of emotion categories from the two main emotion theories to the task; (3) the lack of standardized EA terminology hinders gap identification, comparison, and future goals; and (4) the absence of interdisciplinary research isolates EA from insights in other fields. Our work will enable more focused research into EA and a more holistic approach to modeling emotions in NLP."
}

@inproceedings{alm,
    title = "Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications",
    author = "Ovesdotter Alm, Cecilia",
    editor = "Lin, Dekang  and
      Matsumoto, Yuji  and
      Mihalcea, Rada",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P11-2019/",
    pages = "107--112"
}

@inproceedings{variation,
    title = "The ``Problem'' of Human Label Variation: On Ground Truth in Data, Modeling and Evaluation",
    author = "Plank, Barbara",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.731/",
    doi = "10.18653/v1/2022.emnlp-main.731",
    pages = "10671--10682",
    abstract = "Human variation in labeling is often considered noise. Annotation projects for machine learning (ML) aim at minimizing human label variation, with the assumption to maximize data quality and in turn optimize and maximize machine learning metrics. However, thisconventional practice assumes that there exists a *ground truth*, and neglects that there exists genuine human variation in labeling due to disagreement, subjectivity in annotation or multiple plausible answers.In this position paper, we argue that this big open problem of \textit{human label variation} persists and critically needs more attention to move our field forward. This is because human label variation impacts all stages of the ML pipeline: *data, modeling and evaluation*. However, few works consider all of these dimensions jointly; and existing research is fragmented. We reconcile different previously proposed notions of human label variation, provide a repository of publicly-available datasets with un-aggregated labels, depict approaches proposed so far, identify gaps and suggest ways forward. As datasets are becoming increasingly available, we hope that this synthesized view on the ``problem'' will lead to an open discussion on possible strategies to devise fundamentally new directions."
}

@article{distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}

@article{label_quality,
      title={Improving Label Quality by Jointly Modeling Items and Annotators}, 
      author={Tharindu Cyril Weerasooriya and Alexander G. Ororbia and Christopher M. Homan},
      year={2021},
      eprint={2106.10600},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2106.10600}, 
}

@article{reddit, title={Impact of Reddit Community Culture on User Attitude Expression and Social Interaction}, volume={2}, url={https://www.pioneerpublisher.com/JLCS/article/view/521}, abstractNote={&amp;lt;p&amp;gt;This study delves into the intricate relationship between Reddit’s community culture, user attitude expression, and social interaction. Reddit, a prominent online platform, offers a diverse ecosystem of communities where users express their attitudes, opinions, and beliefs. The research provides insights into how user attitudes influence and are influenced by community norms, how they contribute to the formation of community culture, and the consequences of culture clashes and echo chambers. By examining both qualitative and quantitative aspects, the study seeks to enhance our understanding of online community dynamics and lays the foundation for creating more inclusive and constructive digital spaces.&amp;lt;/p&amp;gt;}, number={4}, journal={Journal of Linguistics and Communication Studies}, author={Lutgardis Oddný and Cecilia Ainslie and Solly Lakshman and Dina Nathan}, year={2023}, month={Oct.}, pages={61–67} }

@inproceedings{negatives_equal,
    title = "Not All Negatives are Equal: {L}abel-Aware Contrastive Loss for Fine-grained Text Classification",
    author = "Suresh, Varsha  and
      Ong, Desmond",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.359/",
    doi = "10.18653/v1/2021.emnlp-main.359",
    pages = "4381--4394",
    abstract = "Fine-grained classification involves dealing with datasets with larger number of classes with subtle differences between them. Guiding the model to focus on differentiating dimensions between these commonly confusable classes is key to improving performance on fine-grained tasks. In this work, we analyse the contrastive fine-tuning of pre-trained language models on two fine-grained text classification tasks, emotion classification and sentiment analysis. We adaptively embed class relationships into a contrastive objective function to help differently weigh the positives and negatives, and in particular, weighting closely confusable negatives more than less similar negative examples. We find that Label-aware Contrastive Loss outperforms previous contrastive methods, in the presence of larger number and/or more confusable classes, and helps models to produce output distributions that are more differentiated."
}

@article{are_we_really,
      title={Are We Really Making Much Progress in Text Classification? A Comparative Review}, 
      author={Lukas Galke and Ansgar Scherp and Andor Diera and Fabian Karl and Bao Xin Lin and Bhakti Khera and Tim Meuser and Tushar Singhal},
      year={2025},
      eprint={2204.03954},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.03954}, 
}

@article{disagreements,
    author = {Davani, Aida Mostafazadeh and Díaz, Mark and Prabhakaran, Vinodkumar},
    title = {Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {10},
    pages = {92-110},
    year = {2022},
    month = {01},
    abstract = {Majority voting and averaging are common approaches used to resolve annotator disagreements and derive single ground truth labels from multiple annotations. However, annotators may systematically disagree with one another, often reflecting their individual biases and values, especially in the case of subjective tasks such as detecting affect, aggression, and hate speech. Annotator disagreements may capture important nuances in such tasks that are often ignored while aggregating annotations to a single ground truth. In order to address this, we investigate the efficacy of multi-annotator models. In particular, our multi-task based approach treats predicting each annotators’ judgements as separate subtasks, while sharing a common learned representation of the task. We show that this approach yields same or better performance than aggregating labels in the data prior to training across seven different binary classification tasks. Our approach also provides a way to estimate uncertainty in predictions, which we demonstrate better correlate with annotation disagreements than traditional methods. Being able to model uncertainty is especially useful in deployment scenarios where knowing when not to make a prediction is important.},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00449},
    url = {https://doi.org/10.1162/tacl\_a\_00449},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00449/1986597/tacl\_a\_00449.pdf},
}





@inproceedings{black_white,
    title = "Beyond Black {\&} White: Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning",
    author = "Fornaciari, Tommaso  and
      Uma, Alexandra  and
      Paun, Silviu  and
      Plank, Barbara  and
      Hovy, Dirk  and
      Poesio, Massimo",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.204/",
    doi = "10.18653/v1/2021.naacl-main.204",
    pages = "2591--2597",
    abstract = "Supervised learning assumes that a ground truth label exists. However, the reliability of this ground truth depends on human annotators, who often disagree. Prior work has shown that this disagreement can be helpful in training models. We propose a novel method to incorporate this disagreement as information: in addition to the standard error computation, we use soft-labels (i.e., probability distributions over the annotator labels) as an auxiliary task in a multi-task neural network. We measure the divergence between the predictions and the target soft-labels with several loss-functions and evaluate the models on various NLP tasks. We find that the soft-label prediction auxiliary task reduces the penalty for errors on ambiguous entities, and thereby mitigates overfitting. It significantly improves performance across tasks, beyond the standard approach and prior work."
}
@article{unknown_reliability,
      title={Training Neural Networks on Data Sources with Unknown Reliability}, 
      author={Alexander Capstick and Francesca Palermo and Tianyu Cui and Payam Barnaghi},
      year={2025},
      eprint={2212.02895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.02895}, 
}

@online{mislabeled,
  author  = {Edwin Chen},
  title   = {30% of Google's Emotions Dataset is Mislabeled},
  year    = {2025},
  url     = {https://www.surgehq.ai/blog/30-percent-of-googles-reddit-emotions-dataset-is-mislabeled},
  urldate = {2025-06-01}
}

@misc{shap,
  title = {An introduction to explainable AI with Shapley values},
  year = {2018},
  author = {Scott Lundberg},
  url = {https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html},
  urldate = {2025-06-01}
}

@article{LIME,
      title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1602.04938},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1602.04938}, 
}

@inproceedings{noise_corr,
    title = "Noise Correction on Subjective Datasets",
    author = "Jinadu, Uthman  and
      Ding, Yi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.294/",
    doi = "10.18653/v1/2024.acl-long.294",
    pages = "5385--5395",
    abstract = "Incorporating every annotator{'}s perspective is crucial for unbiased data modeling. Annotator fatigue and changing opinions over time can distort dataset annotations. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, this method provides a controllable way to encourage or discourage disagreement. We demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data."
}

@inproceedings{data_aug,
author = {Imran, Mia Mohammad and Jain, Yashasvi and Chatterjee, Preetha and Damevski, Kostadin},
title = {Data Augmentation for Improving Emotion Recognition in Software Engineering Communication},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3556925},
doi = {10.1145/3551349.3556925},
abstract = {Emotions (e.g., Joy, Anger) are prevalent in daily software engineering (SE) activities, and are known to be significant indicators of work productivity (e.g., bug fixing efficiency). Recent studies have shown that directly applying general purpose emotion classification tools to SE corpora is not effective. Even within the SE domain, tool performance degrades significantly when trained on one communication channel and evaluated on another (e.g, StackOverflow vs. GitHub comments). Retraining a tool with channel-specific data takes significant effort since manually annotating a large dataset of ground truth data is expensive. In this paper, we address this data scarcity problem by automatically creating new training data using a data augmentation technique. Based on an analysis of the types of errors made by popular SE-specific emotion recognition tools, we specifically target our data augmentation strategy in order to improve the performance of emotion recognition. Our results show an average improvement of 9.3\% in micro F1-Score for three existing emotion classification tools (ESEM-E, EMTk, SEntiMoji) when trained with our best augmentation strategy.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {29},
numpages = {13},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@misc{small_imb,
      title={Data Augmentation for Emotion Detection in Small Imbalanced Text Data}, 
      author={Anna Koufakou and Diego Grisales and Ragy Costa de jesus and Oscar Fox},
      year={2023},
      eprint={2310.17015},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.17015}, 
}

@article{multi_label_emotion,
title = {Multi-label emotion classification in texts using transfer learning},
journal = {Expert Systems with Applications},
volume = {213},
pages = {118534},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118534},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422016098},
author = {Iqra Ameer and Necva Bölücü and Muhammad Hammad Fahim Siddiqui and Burcu Can and Grigori Sidorov and Alexander Gelbukh},
keywords = {Multi-label emotion classification, Bi-LSTM, Transformer Networks, Attention mechanism, Social media},
}


@article{ekman,
author = {Paul Ekman},
title ={Facial Expressions of Emotion: New Findings, New Questions},

journal = {Psychological Science},
volume = {3},
number = {1},
pages = {34-38},
year = {1992},
doi = {10.1111/j.1467-9280.1992.tb00253.x},

URL = { 
    
        https://doi.org/10.1111/j.1467-9280.1992.tb00253.x
    
    

},
eprint = { 
    
        https://doi.org/10.1111/j.1467-9280.1992.tb00253.x
    
    

}
,
    abstract = { The evidence on universals in facial expression of emotion, renewed controversy about that evidence, and new findings on cultural differences are reviewed. New findings on the capability for voluntarily made facial expressions to generate changes in both autonomic and central nervous system activity are discussed, and possible mechanisms by which this could occur are outlined. Finally, new work which has identified how to distinguish the smile of enjoyment from other types of smiling is described. }
}